{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "silar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1G3RmlnOgzaS4tXFnbPkB8j_CWI_0GlUV",
      "authorship_tag": "ABX9TyMhNSKCCLuFf+zmPXN+7sDP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liege1997/Sign-Language-Recognition/blob/main/silar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVMDue9So9Qo"
      },
      "source": [
        "# Project Silar - Sign Language Recognition\n",
        "\n",
        "**Initial methods to import dataset from Kaggle**\n",
        "\n",
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/ProjectSilar')\n",
        "\n",
        "os.listdir()\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "!kaggle datasets download -d grassknoted/asl-alphabet\n",
        "\n",
        "!unzip -q 'american-sign-language-dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0p3voAsvZVj"
      },
      "source": [
        "**References:**\n",
        "\n",
        "https://colab.research.google.com/github/xn2333/OpenCV/blob/master/Image_Processing_in_Python_Final.ipynb#scrollTo=6dy-iP-VTibt\n",
        "\n",
        "https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks\n",
        "\n",
        "https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLbshBSMw43L"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUXL-2nDmwYt",
        "outputId": "89d943d1-9565-4910-d1c2-d7f92319f833"
      },
      "source": [
        "img_folder=\"../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train\"\n",
        "asl_dir = tf.keras.preprocessing.image_dataset_from_directory(img_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25291 files belonging to 36 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqn8nztX6zAp"
      },
      "source": [
        "l0={'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,\n",
        "   'a':10,'b':11,'c':12,'d':13,'e':14,'f':15,'g':16,'h':17,'i':18,'j':19,'k':20,'l':21,'m':22,\n",
        "   'n':23,'o':24,'p':25,'q':26,'r':27,'s':28,'t':29,'u':30,'v':31,'w':32,'x':33,'y':34,'z':35}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twu_ju2ZXNLq"
      },
      "source": [
        "l={'a':10,'b':11,'c':12,'d':13,'e':14,'f':15,'g':16,'h':17,'i':18,'j':19,'k':20,'l':21,'m':22,\n",
        "   'n':23,'o':24,'p':25,'q':26,'r':27,'s':28,'t':29,'u':30,'v':31,'w':32,'x':33,'y':34,'z':35}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvL8DkeVBLGy"
      },
      "source": [
        "img_height = 32\n",
        "img_width = 32\n",
        "load_size = 100 #total images per folder\n",
        "dir_url='../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
        "\n",
        "fgbg1 = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "def create_ds(u,l):\n",
        "    image_ds=[]\n",
        "    labels=[]\n",
        "    for folder_name in l:\n",
        "        folder_path=os.path.join(u,folder_name.upper())\n",
        "        for im in os.listdir(folder_path)[:load_size]:\n",
        "            image=cv2.imread(os.path.join(folder_path,im))\n",
        "            image=cv2.resize(image,(img_height,img_width))\n",
        "            #image=fgbg1.apply(image)\n",
        "            image_ds.append(image)\n",
        "            labels.append(l[folder_name])\n",
        "    return image_ds,labels\n",
        "X,Y=create_ds(dir_url,l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU7-REhg-HKz"
      },
      "source": [
        "X =np.array(X)/255.0 #to range 0-1\n",
        "X=np.reshape(X,(X.shape[0],img_height,img_width,3))\n",
        "X = X.astype('float32')\n",
        "Y=np.array(Y)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VTGk4luXXsL"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(X[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6JPjDs8XjvB"
      },
      "source": [
        "model_dl = keras.Sequential()\n",
        "model_dl.add(Conv2D(16,(3,3),activation=\"relu\",input_shape=(img_height,img_width,3)))\n",
        "model_dl.add(MaxPool2D(2,2))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
        "model_dl.add(MaxPool2D(2,2))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
        "model_dl.add(MaxPool2D(2,2))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Flatten())\n",
        "model_dl.add(Dense(128,activation=\"relu\"))\n",
        "model_dl.add(Dropout(0.2))\n",
        "model_dl.add(Dense(36,activation=\"softmax\"))\n",
        "model_dl.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBNy-iDLXl8N"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)\n",
        "\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau #Import callback functions\n",
        "earlystop=EarlyStopping(patience=10) #Monitor the performance. If it dips, then stop training\n",
        "learning_rate_reduce=ReduceLROnPlateau(monitor=\"val_acc\",min_lr=0.001) #Change learning rate if not performing good enough\n",
        "callbacks=[earlystop,learning_rate_reduce]\n",
        "\n",
        "model_dl.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=callbacks, epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M42-grdXoFj"
      },
      "source": [
        "model_dl.save(\"model_dl.h5\")\n",
        "model_dl = keras.models.load_model(\"model_dl.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw61wZQmXtJw"
      },
      "source": [
        "#WeÂ´ll use any image sample from the Kaggle dataset to test it \n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Creating a dictionary to map each of the indexes to the corresponding number or letter\n",
        "\n",
        "dict = {0:\"0\",1:\"1\",2:\"2\",3:\"3\",4:\"4\",5:\"5\",6:\"6\",7:\"7\",8:\"8\",9:\"9\",10:\"a\",11:\"b\",12:\"c\",13:\"d\",14:\"e\",15:\"f\",16:\"g\",\n",
        "        17:\"h\",18:\"i\",19:\"j\",20:\"k\",21:\"l\",22:\"m\",23:\"n\",24:\"o\",25:\"p\",26:\"q\",27:\"r\",28:\"s\",29:\"t\",30:\"u\",31:\"v\",32:\"w\",\n",
        "        33:\"x\",34:\"y\",35:\"z\"}\n",
        "\n",
        "#Predicting images\n",
        "img_url=\"../input/handgestures/WhatsApp Image 2021-04-28 at 9.36.52 PM (1).jpeg\"\n",
        "#img_url=\"../input/hand-gesture-b/hand.jpeg\"\n",
        "img = image.load_img(img_url, target_size=(img_width, img_height))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "batch_size=32\n",
        "image = np.vstack([x])\n",
        "classes = model_dl.predict_classes(image, batch_size=batch_size)\n",
        "probabilities = model_dl.predict_proba(image, batch_size=batch_size)\n",
        "probabilities_formatted = list(map(\"{:.2f}%\".format, probabilities[0]*100))\n",
        "\n",
        "print(classes) #displaying matrix prediction position\n",
        "\n",
        "print(f'The predicted image corresponds to \"{dict[classes.item()]}\" with {probabilities_formatted[classes.item()]} probability.') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}